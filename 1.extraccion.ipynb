{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de modulos a emplear\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Agregar la carpeta raíz del proyecto a las rutas de búsqueda de Python\n",
    "base_dir = os.getcwd()  # Obtiene el directorio actual (donde está la libreta)\n",
    "sys.path.append(base_dir)  # Agrega la carpeta raíz del proyecto a las rutas de búsqueda\n",
    "\n",
    "# Importar las funciones desde helpers.importar_data\n",
    "from helpers.importar_data import cargar_datos_excel\n",
    "from helpers.guardar_dato import guardar_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las pestañas a cargar\n",
    "sheets_to_load = [\"Base Ventas\", \"Productos\", \"Ciudad\"]\n",
    "\n",
    "# Cargamos los datos desde el Excel\n",
    "datos = cargar_datos_excel(base_dir, sheets=sheets_to_load)\n",
    "\n",
    "# Accesamos a los Dataframes\n",
    "ventas_df = datos[\"Base Ventas\"]\n",
    "productos_df = datos[\"Productos\"]\n",
    "ciudad_df = datos[\"Ciudad\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza del dato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Ventas\n",
    "**Cod_orden** tiene la pinta de ser un identificador unico (**Llave primaria**) para cada pedido, por lo cual verificariamos que no existan duplicados ni valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados en Cod_orden: 0\n",
      "Valores nulos en Cod_orden: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Duplicados en Cod_orden: {ventas_df['Cod_orden'].duplicated().sum()}\")\n",
    "print(f\"Valores nulos en Cod_orden: {ventas_df['Cod_orden'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cod_Producto** tiene los codigos numericos del codigo de cada producto, en este caso seria una **llave foranea** de la **tabla Productos** en la columna que lleva el mismo nombre **Cod_Producto**.\n",
    "\n",
    "Vamos a confirmar que todos los valores correspondan a codigos validos y consistentes y vamos a verificar esta columna con la tabla Productos para verificar la integridad (relación con llaves foráneas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en Cod_Producto: 12\n"
     ]
    }
   ],
   "source": [
    "print(f\"Valores únicos en Cod_Producto: {ventas_df['Cod_Producto'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos 12 valores unicos de productos en la columna Cod_Producto, lo que es consistente con los 12 diferentes productos de la tabla Productos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cod_Ciudad** tiene los codigos numericos de diferentes ciudades, en este caso seria una **llave foranea** de la **tabla Ciudad** en la columna con el mismo nombre *Cod_Ciudad*.\n",
    "\n",
    "Vamos a segurarnos que todos los codigos correspondan a valores válidos de la tabla Ciudad y verificar si hay valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en Cod_Ciudad: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Valores únicos en Cod_Ciudad: {ventas_df['Cod_Ciudad'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos 5 valores unicos de productos en la columna Cod_Ciudad, lo que es consistente con los 5 diferentes productos de la tabla Ciudad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unidades_Vendidas** contiene los valores numericos de ventas de los productos en una fecha determinada. Vamos a verificar si existen valores negativos o cero, asi como revisar la distribucion de las ventas para detectar valores atipicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1299.000000\n",
      "mean        3.099307\n",
      "std         1.424037\n",
      "min         1.000000\n",
      "25%         2.000000\n",
      "50%         3.000000\n",
      "75%         4.000000\n",
      "max         5.000000\n",
      "Name: Unidades_Vendidas, dtype: float64\n",
      "Valores negativos en Unidades_Vendidas: 0\n"
     ]
    }
   ],
   "source": [
    "print(ventas_df['Unidades_Vendidas'].describe())\n",
    "print(f\"Valores negativos en Unidades_Vendidas: {(ventas_df['Unidades_Vendidas'] < 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La desviación estándar es 1.42, lo que indica que las ventas están moderadamente dispersas alrededor de la media.\n",
    "\n",
    "Dado que la media y la mediana son casi iguales, la distribución parece ser simétrica, sin una presencia significativa de valores extremos (outliers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fecha_Orden** contiene las fechas de las unidades vendidas, vamos a confirmar que los valores esten en formato de fecha y buscaremos valores fuera del rango esperado (fechas futuras o inconsistencias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fechas inválidas: 0\n",
      "Rango de fechas: 2024-01-01 00:00:00 - 2024-03-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Cambiamos el tipo de dato a datetime.\n",
    "ventas_df['Fecha_orden'] = pd.to_datetime(ventas_df['Fecha_orden'], errors='coerce')\n",
    "print(f\"Fechas inválidas: {ventas_df['Fecha_orden'].isnull().sum()}\")\n",
    "print(f\"Rango de fechas: {ventas_df['Fecha_orden'].min()} - {ventas_df['Fecha_orden'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No tenemos formatos de fecha invalidas y el rango de fechas va del 01 de enero del 2024 al 31 de marzo del 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tipo_Venta** contiene el giro de quien realizo la venta, Nos vamos a segurar que todos los valores sean consistentes y buscar valores inesperados o mal escritos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en Tipo_Venta: ['TIENDA' 'DOMICILIO']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Valores únicos en Tipo_Venta: {ventas_df['Tipo_Venta'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar los nombres de las columnas a minúsculas\n",
    "ventas_df.columns = ventas_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar por fecha\n",
    "ventas_df = ventas_df.sort_values(by=\"fecha_orden\").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo existen dos valores TIENDA y DOMICILIO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Productos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cod_Producto** contiene el codigo para cada producto, es la **llave primaria de esta tabla** y es una **llave foranea en la tabla Base Ventas**. \n",
    "\n",
    "Vamos a verificar que no haya duplicados y asegurarnos que no existan valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados en Cod_Producto: 0\n",
      "Valores nulos en Cod_Producto: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Duplicados en Cod_Producto: {productos_df['Cod_Producto'].duplicated().sum()}\")\n",
    "print(f\"Valores nulos en Cod_Producto: {productos_df['Cod_Producto'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nom_producto** contiene los nombres de los productos, vamos a revisar si tenemos valores duplicados y comprobar que no existan nombres en blanco o nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados en Nom_producto: 0\n",
      "Valores nulos en Nom_producto: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Duplicados en Nom_producto: {productos_df['Nom_producto'].duplicated().sum()}\")\n",
    "print(f\"Valores nulos en Nom_producto: {productos_df['Nom_producto'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precio_Unitario** y **Costo_Unitario** contienen los costos y precios unitarios de los productos. Vamos a convertir los valores a formato numerico para conservar solo numeros (la columna cuanta con simbolos como *$* y comas). \n",
    "\n",
    "\n",
    "Nos vamos a asegurar de que Costo_Unitario sea menor o igual a Precio_Unitario, pues esta no deberian haber productos que se vendan por debajo de su costo.\n",
    "\n",
    "Revisaremos posibles valores extremos o atípicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Productos con Costo_Unitario mayor al Precio_Unitario:\n",
      "Empty DataFrame\n",
      "Columns: [Cod_Producto, Nom_producto, Precio_Unitario, Categoria, Costo_Unitario]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Convertir columnas a numérico eliminando el símbolo de dólar y las comas\n",
    "productos_df['Precio_Unitario'] = productos_df['Precio_Unitario'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "productos_df['Costo_Unitario'] = productos_df['Costo_Unitario'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# Verificar si hay inconsistencias de costo/precio\n",
    "inconsistencia_costo = productos_df[productos_df['Costo_Unitario'] > productos_df['Precio_Unitario']]\n",
    "print(\"Productos con Costo_Unitario mayor al Precio_Unitario:\")\n",
    "print(inconsistencia_costo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categoria** contiene valores categoricos de la calidad del producto, vamos a revisar los valores únicos para detectar categorías mal escritas o inconsistentes, asi como la cantidad de productos que pertenecen a cada categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorías únicas: ['MEGA' 'BARRILITO' 'PREMIUM']\n",
      "Conteo por categoría:\n",
      "Categoria\n",
      "MEGA         4\n",
      "BARRILITO    4\n",
      "PREMIUM      4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Categorías únicas: {productos_df['Categoria'].unique()}\")\n",
    "print(\"Conteo por categoría:\")\n",
    "print(productos_df['Categoria'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que hay 3 tipos de categorias:\n",
    "* MEGA.\n",
    "* BARRILITO.\n",
    "* PREMIUM.\n",
    "\n",
    "Se tienen 4 productos para cada categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar los nombres de las columnas a minúsculas\n",
    "productos_df.columns = productos_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ciudad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cod_ciudad** contiene el codigo numerico asignado a diferentes ciudades. Vamos a verificar que cada código sea único, ademas de asegurarnos de que no existen valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados en Cod_ciudad: 0\n",
      "Valores nulos en Cod_ciudad: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Duplicados en Cod_ciudad: {ciudad_df['Cod_ciudad'].duplicated().sum()}\")\n",
    "print(f\"Valores nulos en Cod_ciudad: {ciudad_df['Cod_ciudad'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores unicos de en Con_ciudad: [1 2 3 4 5 nan\n",
      " '*El costo del domicilio es el mismo sin importar el número de unidades de la orden']\n"
     ]
    }
   ],
   "source": [
    "# Revisamos los valores nulos en la columna Cod_ciudad\n",
    "print(f\"Valores unicos de en Con_ciudad: {ciudad_df['Cod_ciudad'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en Cod_ciudad después de limpiar: [1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# Eliminar filas con el valor inválido\n",
    "ciudad_df = ciudad_df[ciudad_df['Cod_ciudad'] != '*El costo del domicilio es el mismo sin importar el número de unidades de la orden']\n",
    "\n",
    "# Manejar valores nulos (opción: eliminar)\n",
    "ciudad_df = ciudad_df.dropna(subset=['Cod_ciudad'])\n",
    "\n",
    "# Revisión de valores únicos después de limpiar\n",
    "print(f\"Valores únicos en Cod_ciudad después de limpiar: {ciudad_df['Cod_ciudad'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna **Ciudad** contienelos nombres de las ciudades. Vamos a revisar los nombres de las ciudades para detectar inconsistencias como duplicados con errores de escritura o espacios en blanco, ademas, vamos a normalizar los nombres (minisculas, sin espacios adicionales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciudades únicas: ['BOGOTA' 'LIMA' 'MONTERREY' 'LEÓN' 'MADRID']\n",
      "Ciudades normalizadas: ['BOGOTA' 'LIMA' 'MONTERREY' 'LEÓN' 'MADRID']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ciudades únicas: {ciudad_df['Ciudad'].unique()}\")\n",
    "ciudad_df['Ciudad'] = ciudad_df['Ciudad'].str.strip().str.upper()  # Normalizar\n",
    "print(f\"Ciudades normalizadas: {ciudad_df['Ciudad'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Costo_Asociado_al_domicilio** incluye el valor en unidades de dinero por el envio a domicilio dependiendo las ciudades. Vamos a convertir el costo a formato numérico (elimina símbolos $ y comas) y verficar si hay valores nulos o inconsistencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciudad_df['Costo_Asociado_al_domicilio'] = ciudad_df['Costo_Asociado_al_domicilio'].replace('[\\$,]', '', regex=True).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar los nombres de las columnas a minúsculas\n",
    "ciudad_df.columns = ciudad_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar lo datos limpios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo limpio guardado en: f:\\Python\\Entrevistas\\modelo\\data\\procesados\\ventas_limpio.csv\n",
      "Archivo limpio guardado en: f:\\Python\\Entrevistas\\modelo\\data\\procesados\\productos_limpio.csv\n",
      "Archivo limpio guardado en: f:\\Python\\Entrevistas\\modelo\\data\\procesados\\ciudad_limpio.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'f:\\\\Python\\\\Entrevistas\\\\modelo\\\\data\\\\procesados\\\\ciudad_limpio.csv'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar el dataframe limpio de ventas\n",
    "guardar_dataframe(ventas_df, base_dir, \"ventas_limpio.csv\")\n",
    "# Guardar el dataframe limpio de productos\n",
    "guardar_dataframe(productos_df, base_dir, \"productos_limpio.csv\")\n",
    "# Guardar el dataframe limpio de ciudad\n",
    "guardar_dataframe(ciudad_df, base_dir, \"ciudad_limpio.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
